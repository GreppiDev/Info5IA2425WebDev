# Template Script di configurazione di Nginx per la web app EducationalGames

# Definisce un'area di memoria condivisa per il rate limiting.
# 10m = 10 megabytes, sufficienti per circa 160.000 indirizzi IP.
# rate=10r/s: permette una media di 10 richieste al secondo per IP.
limit_req_zone $binary_remote_addr zone=app_rate_limit:10m rate=10r/s;
# Cosa fa: Questo comando crea e configura uno "strumento" per il rate limiting.
# Nome dello strumento: app_rate_limit.
# Come funziona: Traccia gli indirizzi IP ($binary_remote_addr) in un'area di memoria condivisa di 10MB.
# Regola base: Permette una media di 10 richieste al secondo (rate=10r/s).
# In questo momento, lo strumento è pronto nella cassetta, ma non sta ancora limitando nessuna richiesta.

# Per usare il rate limiting, si scrive: limit_req zone=app_rate_limit ...; nella location opportuna

# Definisce il percorso e i parametri della cache per i file statici.
# keys_zone=static_cache:10m: definisce una zona di memoria di 10MB per le chiavi della cache.
# inactive=60m: rimuove gli elementi dalla cache se non vengono richiesti per 60 minuti.
# max_size=1g: imposta la dimensione massima della cache su disco a 1GB.
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=static_cache:10m inactive=60m max_size=1g;
# Cosa fa: Questo comando crea e configura uno "spazio" per la cache.
# Dove si trova: Sul disco, nella cartella /var/cache/nginx.
# Come è organizzato: Con una struttura a due livelli di directory (levels=1:2) per ottimizzare le performance.
# Come si chiama: Lo spazio di cache ha una zona di chiavi in memoria chiamata static_cache per trovare velocemente i file.
# Regole di pulizia: I file non usati per 60 minuti (inactive=60m) vengono rimossi, e la dimensione totale non può superare 1GB (max_size=1g).
# Anche in questo caso, la cache è pronta e configurata, ma non sta ancora salvando nessun file.

# Per usare la cache, si scrive: proxy_cache static_cache; nella location opportuna

# Definisce l'upstream per le istanze della webapp
upstream educationalgames_backend {

    # 1. IP Hash (Affinità di Sessione basata su IP)
    # Garantisce che le richieste da uno stesso client vadano sempre alla stessa istanza.
    # Utile per applicazioni stateful o per migliorare le performance della cache locale.
    #ip_hash;

    # 2. Least Connections
    # Invia le richieste all'istanza con il minor numero di connessioni attive.
    # Ottimo per distribuire il carico in modo efficiente.
    least_conn;

    # 3. Round Robin (Default)
    # Se non si specifica alcuna direttiva, Nginx usa il Round Robin,
    # inviando le richieste alle istanze in sequenza.
    
    # Usa la variabile per la porta interna della webapp
    server webapp:${WEBAPP_CONTAINER_INTERNAL_PORT} max_fails=3 fail_timeout=30s;
    
    # Abilita la condivisione delle connessioni upstream per migliorare le performance.
    keepalive 32;
    # Scenario Standard (senza keepalive)
    
    # Un client (browser) invia una richiesta a Nginx.
    # Nginx deve inoltrare questa richiesta alla tua webapp. Per farlo, apre una nuova connessione di rete (TCP) verso il container della webapp.
    # Avviene l'handshake TCP (il "saluto" a tre vie: SYN, SYN-ACK, ACK) per stabilire la connessione. Questo richiede tempo e risorse.
    # Nginx invia la richiesta, la webapp risponde.
    # Nginx riceve la risposta e la inoltra al client.
    # Nginx chiude immediatamente la connessione con la webapp.
    # Per la richiesta successiva, anche se arriva un millisecondo dopo, l'intero processo dal punto 2 al punto 6 si ripete da capo.
    # Questo approccio è inefficiente, specialmente con un traffico elevato, perché aprire e chiudere connessioni di rete continuamente è un'operazione costosa in termini di CPU e latenza.

    # Scenario Ottimizzato (con keepalive)
    # Cosa fa: Dice a Nginx: "Quando hai finito di usare una connessione con un server upstream, non chiuderla subito. Tienila aperta e mettila in una cache di connessioni inattive, pronta per essere riutilizzata."

    # Alla prima richiesta, Nginx apre una connessione con la webapp come prima.
    # Dopo che la richiesta è stata servita, Nginx non chiude la connessione, ma la mantiene in uno stato "idle" (inattivo).
    # Quando arriva una nuova richiesta per lo stesso upstream, Nginx prende la connessione già aperta e pronta dalla sua cache e la riutilizza immediatamente, saltando completamente il costoso handshake TCP.
    # Il numero 32 specifica la dimensione massima della cache di connessioni inattive che ogni processo worker di Nginx manterrà per questo gruppo di upstream. Non è un timeout. Significa che ogni worker può tenere pronte fino a 32 connessioni da riutilizzare.
}

# Server HTTP: reindirizza tutto a HTTPS
server {
    listen 80;
    listen [::]:80;
    server_name ${NGINX_SERVER_NAME};

    location / {
        return 301 https://${NGINX_SERVER_NAME}:${NGINX_HTTPS_HOST_PORT}$request_uri;
    }
}

# Server HTTPS (con certificati di sviluppo)
server {
    listen 443 ssl;
    listen [::]:443 ssl;
    http2 on;
    server_name ${NGINX_SERVER_NAME};

    # Assicurarsi che i nomi dei certificati siano corretti o usa NGINX_SERVER_NAME
    ssl_certificate /etc/nginx/ssl/dev-certs/${NGINX_SERVER_NAME}.crt;
    ssl_certificate_key /etc/nginx/ssl/dev-certs/${NGINX_SERVER_NAME}.key;

    # Impostazioni SSL consigliate (puoi personalizzarle)
    
    ssl_protocols TLSv1.2 TLSv1.3;
    # Cosa fa: Specifica quali versioni del protocollo TLS il server accetterà.
    # Si abilitano TLS 1.2 e TLS 1.3, che sono le versioni moderne e sicure. Le versioni più vecchie e vulnerabili (SSLv3, TLS 1.0, TLS 1.1) sono correttamente disabilitate.
    
    ssl_prefer_server_ciphers off;
    # Cosa fa: Impostando la direttiva su off, diciamo a Nginx: "Durante l'handshake TLS, rispetta l'ordine di preferenza degli algoritmi di cifratura proposto dal client".
    # Perché questa è la best practice moderna?
    # Performance su Client Moderni: I browser e i sistemi operativi moderni sono ottimizzati per usare gli algoritmi più performanti per la loro specifica architettura hardware (es. CPU con accelerazione hardware per AES-NI). Permettere al client di scegliere il suo algoritmo preferito (tra quelli sicuri che il server supporta) può portare a un piccolo ma misurabile miglioramento delle performance.
    # Sicurezza con TLS 1.3: Con TLS 1.3, il concetto di "preferenza del server" è quasi obsoleto. Il protocollo stesso è stato semplificato e ha un set molto più ristretto e sicuro di algoritmi. L'handshake è diverso e la scelta del client è più rilevante. Mantenere off è più allineato con la filosofia di TLS 1.3.
    # Meno Manutenzione: Non ci si deve più preoccupare di mantenere una lista ssl_ciphers perfettamente ordinata. Finché il server supporta solo algoritmi forti, qualsiasi scelta fatta dal client sarà una scelta sicura.

    ssl_session_cache shared:SSL:10m;
    # Cosa fa: Abilita una cache lato server per le sessioni TLS. Quando un client si riconnette, può riutilizzare i parametri della sessione precedente senza dover rieseguire da capo il costoso handshake crittografico.
    # shared:SSL:10m significa: crea una cache di nome "SSL", condivisa tra tutti i processi worker di Nginx, con una dimensione di 10 megabyte.
    # Migliora significativamente le performance per connessioni ripetute.
   
    ssl_session_timeout 1d;
    # Cosa fa: Imposta la durata di validità di una sessione nella cache. In questo caso, un client può riutilizzare una sessione per 1 giorno.
    
    ssl_session_tickets off;
    # Cosa fa: Disabilita i "session ticket", un'alternativa alla cache di sessione lato server. Con i ticket, è il client a conservare i dati di sessione (criptati dal server). Sebbene più efficienti in cluster molto grandi, hanno alcune debolezze di sicurezza (non garantiscono Perfect Forward Secrecy se la chiave del ticket viene compromessa). Disabilitarli è spesso la scelta più sicura se si usa già ssl_session_cache.
    
    # Header di sicurezza (opzionali ma consigliati)
    add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload" always;
    # Cosa fa: Forza il browser a comunicare con il sito solo tramite HTTPS per un lungo periodo (max-age è in secondi, qui circa 2 anni). Impedisce attacchi di tipo "man-in-the-middle" che tentano di declassare la connessione a HTTP.
    
    add_header X-Frame-Options "SAMEORIGIN" always;
    # Cosa fa: Impedisce che la pagina venga caricata all'interno di un <iframe>, <frame>, <embed> o <object> su un sito diverso dal tuo. È la difesa principale contro gli attacchi di Clickjacking, dove un utente viene ingannato a cliccare su qualcosa di diverso da ciò che pensa.
    # "SAMEORIGIN": Permette l'uso di frame solo se la pagina genitore proviene dallo stesso dominio.
    
    add_header X-Content-Type-Options "nosniff" always;
    # Cosa fa: Impedisce al browser di "indovinare" il tipo di contenuto di un file (MIME sniffing).
    # Se un utente carica un file che sembra un'immagine (.jpg) ma in realtà contiene codice JavaScript, questo header impedisce al browser di eseguirlo.
    
    add_header X-XSS-Protection "1; mode=block" always;
    # Cosa fa: Abilita il filtro anti-Cross-Site Scripting (XSS) integrato nei browser più vecchi (es. IE, Safari). Se rileva un potenziale attacco XSS, impedisce il caricamento della pagina.
    # Nota: I browser moderni si affidano di più all'header Content-Security-Policy, ma questo fornisce comunque un'utile protezione aggiuntiva per una maggiore compatibilità.
    
    add_header Referrer-Policy "no-referrer-when-downgrade" always;
    # Cosa fa: Controlla quali informazioni sulla pagina di provenienza (il "referrer") vengono inviate quando un utente naviga dal tuo sito a un altro.
    # "no-referrer-when-downgrade": Invia il referrer completo quando si naviga verso un sito HTTPS, ma non invia nulla se si naviga da HTTPS a un sito HTTP non sicuro.
    
    # Ottimizzazioni per le performance del proxy.
    proxy_buffering on;
    # Cosa fa: È l'interruttore principale. Quando è on (impostazione predefinita), Nginx abilita il buffering della risposta dal server backend. La risposta viene letta e salvata in memoria prima di essere inviata al client.
    # Perché: Permette a Nginx di ricevere l'intera risposta dalla webapp rapidamente, chiudere la connessione con essa e liberarla. Se fosse off, Nginx dovrebbe inviare i dati al client alla stessa velocità con cui li riceve dal backend, tenendo occupata la webapp per tutto il tempo.
    proxy_buffer_size 16k;
    proxy_buffers 8 16k;
    # Queste due direttive lavorano insieme per definire la dimensione del buffer.
    # proxy_buffer_size 16k;: Definisce la dimensione del primo buffer, usato per memorizzare la parte iniziale della risposta del backend (principalmente gli header HTTP). Deve essere abbastanza grande da contenere tutti gli header. 16k è una dimensione generosa e sicura.
    # proxy_buffers 8 16k;: Se la risposta è più grande del primo buffer, Nginx alloca buffer aggiuntivi. Questa direttiva dice: "Alloca fino a 8 buffer, ciascuno di 16k". La dimensione totale del buffer in memoria sarà quindi 16k + (8 * 16k) = 144k.
    # Cosa succede se la risposta è ancora più grande? Se la risposta supera i 144k, la parte eccedente verrà scritta in un file temporaneo su disco, il che è più lento della memoria ma evita che Nginx esaurisca la RAM.
    client_body_buffer_size 128k;
    # Cosa fa: Questa direttiva riguarda la direzione opposta: dal client a Nginx. Definisce un buffer per leggere il corpo della richiesta del client (ad esempio, quando un utente carica un file o invia un form con molti dati). Se il corpo della richiesta è più grande di questo buffer, viene scritto su disco.
    # Perché: Permette a Nginx di ricevere l'intero upload dal client prima di iniziare a inviarlo al backend, riducendo il tempo in cui la connessione con il backend deve rimanere aperta in attesa dei dati dal client.
    proxy_connect_timeout 60s;
    # Cosa fa: Definisce il tempo massimo (60 secondi) che Nginx attenderà per stabilire una connessione con il server backend (webapp). Se il backend non risponde all'handshake TCP entro questo tempo, Nginx restituirà un errore 504 Gateway Time-out.
    proxy_send_timeout 60s;
    # Cosa fa: Imposta il timeout per l'invio di dati al backend. Se il backend smette di leggere i dati per 60 secondi mentre Nginx sta scrivendo, la connessione viene chiusa.
    proxy_read_timeout 60s;
    # Cosa fa: Imposta il timeout per la lettura di dati dal backend. Se Nginx sta leggendo la risposta e il backend non invia dati per 60 secondi, la connessione viene chiusa.

    # Come Nginx Decide Quale Blocco Usare: La Priorità
    # Nginx non legge i blocchi dall'alto in basso. Segue un algoritmo di priorità preciso:

    # Prima controlla i match di prefisso e ricorda quello più lungo e specifico.
    # Poi controlla TUTTI i match con espressione regolare (~ e ~*) nell'ordine in cui appaiono nel file.
    # Se trova un match con espressione regolare, usa QUELLO e smette di cercare.
    # Se NESSUNA espressione regolare corrisponde, allora usa il match di prefisso che aveva memorizzato al punto 1.



    # Confronto tra Tipi di Direttive

    # Direttive di Impostazione/Modifica (Ereditabili):
    # proxy_set_header
    # proxy_connect_timeout
    # proxy_buffering
    # add_header
    # Queste direttive modificano la richiesta o il modo in cui viene gestita. 
    # Se non sono definite in una location, vengono ereditate dal blocco server. 
    #Per questo motivo, spostarle a livello del server è una buona pratica (DRY).
    
    # Direttive di Azione (NON Ereditabili in questo modo):
    # proxy_pass
    # return
    # rewrite
    # try_files
    # Queste direttive terminano la fase di ricerca e dicono a Nginx quale contenuto servire. 
    # Devono essere presenti all'interno del blocco location che le deve eseguire.

    # Osservazione importante sull'ereditarietà
    # il meccanismo di ereditarietà di Nginx funziona in questo modo:
    # Ereditarietà "Tutto o Niente": Una location eredita le direttive proxy_set_header dal blocco server genitore. 
    # Tuttavia, se all'interno della location si definisce anche una sola direttiva proxy_set_header, l'ereditarietà per tutti gli altri proxy_set_header si interrompe.
    
    location ~ ^/(metrics|health)$|^/api/telemetry/ {
        # Consenti solo l'accesso da indirizzi IP specifici.
        allow 127.0.0.1; # localhost
        allow ::1; # localhost IPv6
        allow 10.0.0.0/8; # Rete privata classe A
        allow 172.16.0.0/12; # Rete privata classe B - Include Docker
        allow 192.168.0.0/16; # Rete privata classe C
        deny all; # Blocca tutto il resto
        
        # Applica un limite di richieste più restrittivo per l'health check.
        limit_req zone=app_rate_limit burst=5 nodelay;
        # Inoltra le richieste al backend.
        proxy_pass http://educationalgames_backend;
        #Headers per il proxy 
        proxy_set_header Host $host; # L'host originale richiesti dal client (incluso eventuale porta)
        proxy_set_header X-Real-IP $remote_addr; # L'IP reale del client
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # Lista degli IP (client, eventuali proxy)
        proxy_set_header X-Forwarded-Proto $scheme; # Lo schema originale (http o https)
        proxy_set_header X-Forwarded-Host $http_host; # L'host originale inclusa la porta, se specificata dal client
        proxy_http_version 1.1;

        # La versione open-source non supporta health_check attivo.
        # Usiamo il passive health check tramite upstream max_fails/fail_timeout.
    }

    # Location per i file statici (immagini, css, js, etc.).
    location ~* \.(jpg|jpeg|png|gif|ico|css|js|svg|woff|woff2|ttf)$ {
        # Nessun rate limiting per i file statici
        #  se un utente carica una pagina con 30 piccole icone, potrebbe attivare il limite e vedere la pagina "rotta", 
        # anche se il carico sul server è minimo. Si protegge ciò che è prezioso, non ciò che è a basso costo.

        # Inoltra le richieste al backend la prima volta che vengono ricevute.
        proxy_pass http://educationalgames_backend;
        #Headers per il proxy 
        proxy_set_header Host $host; # L'host originale richiesti dal client (incluso eventuale porta)
        proxy_set_header X-Real-IP $remote_addr; # L'IP reale del client
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # Lista degli IP (client, eventuali proxy)
        proxy_set_header X-Forwarded-Proto $scheme; # Lo schema originale (http o https)
        proxy_set_header X-Forwarded-Host $http_host; # L'host originale inclusa la porta, se specificata dal client
        proxy_http_version 1.1;
        # Per le richieste successive, utilizza la cache definita in 'proxy_cache_path'.
        # Utilizza la cache definita in 'proxy_cache_path'.
        proxy_cache static_cache;
        # Considera validi i codici di stato 200, 301, 302 per 1 ora.
        proxy_cache_valid 200 301 302 60m;
        # Se il backend restituisce un errore, usa una versione "scaduta" della risorsa se disponibile.
        proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;
        # Aggiunge un header per indicare lo stato della cache (HIT, MISS, etc.).
        add_header X-Proxy-Cache $upstream_cache_status;
        expires 1d; # Il browser può effettuare la cache di questi file per 1 giorno.
        access_log off; # Disabilita i log di accesso per i file statici per ridurre l'I/O.
        
    }

    # Location specifica per SignalR con timeout lunghi
    # location /chatHub { # <-- Sostituisci con il vero path del tuo hub SignalR
    #     proxy_pass http://educationalgames_backend;
    #     # Headers per WebSocket
    #     proxy_set_header Upgrade $http_upgrade;
    #     proxy_set_header Connection "upgrade";
    #     # Timeout lunghissimi SOLO per questa connessione
    #     proxy_read_timeout 86400s;
    #     proxy_send_timeout 86400s;
    # }

    location / {
        limit_req zone=app_rate_limit burst=20 nodelay;
        proxy_pass http://educationalgames_backend;
        #Headers per il proxy 
        proxy_set_header Host $host; # L'host originale richiesti dal client (incluso eventuale porta)
        proxy_set_header X-Real-IP $remote_addr; # L'IP reale del client
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # Lista degli IP (client, eventuali proxy)
        proxy_set_header X-Forwarded-Proto $scheme; # Lo schema originale (http o https)
        proxy_set_header X-Forwarded-Host $http_host; # L'host originale inclusa la porta, se specificata dal client
        proxy_http_version 1.1;
        # Headers per supportare WebSocket/SignalR se necessario
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }


    # Esempio per servire file statici direttamente da Nginx (se necessario)
    # location /static/ {
    #     alias /var/www/static/;
    #     expires 1d;
    #     access_log off;
    # }

}